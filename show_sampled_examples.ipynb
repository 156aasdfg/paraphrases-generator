{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "def get_bleu(sampled, target):\n",
    "    result = []\n",
    "    sampled = [s.split() for s in sampled]\n",
    "    sampled_list = [[s] for s in sampled]\n",
    "    return nltk.translate.bleu_score.corpus_bleu(list_of_references=sampled_list, hypotheses=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu target = 0.14897870206874952, bleu source = 0.07018395804022802\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>sampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woman with blue dress sitting in modern chair ...</td>\n",
       "      <td>a barefoot woman sitting in a chair relaxing</td>\n",
       "      <td>a lady sitting in a chair outside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an orange is on the white line on a street and...</td>\n",
       "      <td>an orange lying near the white stripe of a hig...</td>\n",
       "      <td>several cars waiting for the side of a race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a girl sitting on a bench in front of a stone ...</td>\n",
       "      <td>a woman sitting on a bench in a stone alcove</td>\n",
       "      <td>a girl sitting on a bench in front of a mural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  woman with blue dress sitting in modern chair ...   \n",
       "1  an orange is on the white line on a street and...   \n",
       "2  a girl sitting on a bench in front of a stone ...   \n",
       "\n",
       "                                              target  \\\n",
       "0       a barefoot woman sitting in a chair relaxing   \n",
       "1  an orange lying near the white stripe of a hig...   \n",
       "2       a woman sitting on a bench in a stone alcove   \n",
       "\n",
       "                                          sampled  \n",
       "0               a lady sitting in a chair outside  \n",
       "1     several cars waiting for the side of a race  \n",
       "2   a girl sitting on a bench in front of a mural  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled = np.load('logs/sampled_out_mscoco_test_snli_200kit_600_800.txt.npy')\n",
    "target = np.load('logs/target_out_mscoco_test_snli_200kit_600_800.txt.npy')\n",
    "source = np.load('logs/source_out_mscoco_test_snli_200kit_600_800.txt.npy')\n",
    "print('bleu target = {}, bleu source = {}'.format(get_bleu(sampled, target), get_bleu(sampled, source)))\n",
    "source = [' '.join(x) for x in source]\n",
    "target = [' '.join(x) for x in target]\n",
    "df = pd.DataFrame(data=np.array([source, target, sampled]).T, columns=['source', 'target', 'sampled'])\n",
    "df.to_csv('logs/mscoco_sampled_snli_200kit_600_800.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu target = 0.18693956466070394, bleu source = 0.07126126638823824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>sampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a black sculpture of a torso is on the floor n...</td>\n",
       "      <td>a living room with tv and entertainment center...</td>\n",
       "      <td>a sculpture with black hair and tattoos on an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a man on a skateboard with a hat</td>\n",
       "      <td>a skateboarder jumping over an obstacle on his...</td>\n",
       "      <td>a skateboarder jumping over an obstacle on hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>half a dozen donuts are sitting in a box</td>\n",
       "      <td>six donuts all being a different kind of flavor</td>\n",
       "      <td>several four pieces of donuts are in a factory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  a black sculpture of a torso is on the floor n...   \n",
       "1                   a man on a skateboard with a hat   \n",
       "2           half a dozen donuts are sitting in a box   \n",
       "\n",
       "                                              target  \\\n",
       "0  a living room with tv and entertainment center...   \n",
       "1  a skateboarder jumping over an obstacle on his...   \n",
       "2    six donuts all being a different kind of flavor   \n",
       "\n",
       "                                             sampled  \n",
       "0   a sculpture with black hair and tattoos on an...  \n",
       "1   a skateboarder jumping over an obstacle on hi...  \n",
       "2     several four pieces of donuts are in a factory  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled = np.load('logs/sampled_out_mscoco_test_mean_snli_200kit_600_800.txt.npy')\n",
    "target = np.load('logs/target_out_mscoco_test_mean_snli_200kit_600_800.txt.npy')\n",
    "source = np.load('logs/source_out_mscoco_test_mean_snli_200kit_600_800.txt.npy')\n",
    "\n",
    "print('bleu target = {}, bleu source = {}'.format(get_bleu(sampled, target), get_bleu(sampled, source)))\n",
    "source = [' '.join(x) for x in source]\n",
    "target = [' '.join(x) for x in target]\n",
    "df = pd.DataFrame(data=np.array([source, target, sampled]).T, columns=['source', 'target', 'sampled'])\n",
    "df.to_csv('logs/mscoco_sampled_MEAN_snli_200kit_600_800.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_result_25kvocab160kit600decrnn.npy\r\n",
      "ce_result_25kvocab160kit.npy\r\n",
      "ce_result_snli_quora_160k.npy\r\n",
      "ce_result_snli_quora_200k_800rnn.npy\r\n",
      "ce_result_train_interm_snli_250kit_600_800.npy\r\n",
      "ce_result_train_mscoco_300kit_600_800.npy\r\n",
      "ce_result_train_quora_coco_200kit_600_600.npy\r\n",
      "ce_result_train_quora_coco_250k800_800.npy\r\n",
      "ce_result_train_quora_coco_250kit_600_800.npy\r\n",
      "ce_result_train_quoraonly120kit600decrnn.npy\r\n",
      "ce_result_train_snli_200k600_600.npy\r\n",
      "ce_result_train_snli_200kit_600_800.npy\r\n",
      "ce_result_train_snli_coco_250kit_600_800.npy\r\n",
      "ce_result_train_snli_coco_250kit_800_800.npy\r\n",
      "ce_result_train_snli_quora_150k_600rnn.npy\r\n",
      "ce_result_train_snli_quora_250k_600_800rnn.npy\r\n",
      "ce_result_train_snli_quora_250k800_1100.npy\r\n",
      "ce_result_train_snli_quora_250kit_600_600.npy\r\n",
      "ce_result_train_snli_quora_250kit_600_800.npy\r\n",
      "ce_result_train_snli_quora_wd_01_200k800_800.npy\r\n",
      "ce_result_valid_interm_snli_250kit_600_800.npy\r\n",
      "ce_result_valid_mscoco_300kit_600_800.npy\r\n",
      "ce_result_valid_quora_coco_200kit_600_600.npy\r\n",
      "ce_result_valid_quora_coco_250k800_800.npy\r\n",
      "ce_result_valid_quora_coco_250kit_600_800.npy\r\n",
      "ce_result_valid_quoraonly120kit600decrnn.npy\r\n",
      "ce_result_valid_snli_200k600_600.npy\r\n",
      "ce_result_valid_snli_200kit_600_800.npy\r\n",
      "ce_result_valid_snli_coco_250kit_600_800.npy\r\n",
      "ce_result_valid_snli_coco_250kit_800_800.npy\r\n",
      "ce_result_valid_snli_quora_150k_600rnn.npy\r\n",
      "ce_result_valid_snli_quora_250k_600_800rnn.npy\r\n",
      "ce_result_valid_snli_quora_250k800_1100.npy\r\n",
      "ce_result_valid_snli_quora_250kit_600_600.npy\r\n",
      "ce_result_valid_snli_quora_250kit_600_800.npy\r\n",
      "ce_result_valid_snli_quora_wd_01_200k800_800.npy\r\n",
      "generated_samples.txt\r\n",
      "intermediate\r\n",
      "kld_result_npy_25kvocab160kit600decrnn.npy\r\n",
      "kld_result_npy_25kvocab160kit.npy\r\n",
      "kld_result_npy_snli_quora_160k.npy\r\n",
      "kld_result_npy_snli_quora_200k_800rnn.npy\r\n",
      "kld_result_train_interm_snli_250kit_600_800.npy\r\n",
      "kld_result_train_mscoco_300kit_600_800.npy\r\n",
      "kld_result_train_quora_coco_200kit_600_600.npy\r\n",
      "kld_result_train_quora_coco_250k800_800.npy\r\n",
      "kld_result_train_quora_coco_250kit_600_800.npy\r\n",
      "kld_result_train_quoraonly120kit600decrnn.npy\r\n",
      "kld_result_train_snli_200k600_600.npy\r\n",
      "kld_result_train_snli_200kit_600_800.npy\r\n",
      "kld_result_train_snli_coco_250kit_600_800.npy\r\n",
      "kld_result_train_snli_coco_250kit_800_800.npy\r\n",
      "kld_result_train_snli_quora_150k_600rnn.npy\r\n",
      "kld_result_train_snli_quora_250k_600_800rnn.npy\r\n",
      "kld_result_train_snli_quora_250k800_1100.npy\r\n",
      "kld_result_train_snli_quora_250kit_600_600.npy\r\n",
      "kld_result_train_snli_quora_250kit_600_800.npy\r\n",
      "kld_result_train_snli_quora_wd_01_200k800_800.npy\r\n",
      "kld_result_valid_interm_snli_250kit_600_800.npy\r\n",
      "kld_result_valid_mscoco_300kit_600_800.npy\r\n",
      "kld_result_valid_quora_coco_200kit_600_600.npy\r\n",
      "kld_result_valid_quora_coco_250k800_800.npy\r\n",
      "kld_result_valid_quora_coco_250kit_600_800.npy\r\n",
      "kld_result_valid_quoraonly120kit600decrnn.npy\r\n",
      "kld_result_valid_snli_200k600_600.npy\r\n",
      "kld_result_valid_snli_200kit_600_800.npy\r\n",
      "kld_result_valid_snli_coco_250kit_600_800.npy\r\n",
      "kld_result_valid_snli_coco_250kit_800_800.npy\r\n",
      "kld_result_valid_snli_quora_150k_600rnn.npy\r\n",
      "kld_result_valid_snli_quora_250k_600_800rnn.npy\r\n",
      "kld_result_valid_snli_quora_250k800_1100.npy\r\n",
      "kld_result_valid_snli_quora_250kit_600_600.npy\r\n",
      "kld_result_valid_snli_quora_250kit_600_800.npy\r\n",
      "kld_result_valid_snli_quora_wd_01_200k800_800.npy\r\n",
      "sampled_out_600.txt.npy\r\n",
      "sampled_out_likely_snli_quora_200k_800rnn.txt.npy\r\n",
      "sampled_out_mean_quora_coco_200kit_600_600.txt.npy\r\n",
      "sampled_out_mean_quora_coco_250k800_800.txt.npy\r\n",
      "sampled_out_mean_quora_coco_250kit_600_800.txt.npy\r\n",
      "sampled_out_mscoco_300kit_600_800.txt.npy\r\n",
      "sampled_out_mscoco_test_mscoco_300kit_600_800.txt.npy\r\n",
      "sampled_out_mscoco_test_quora_coco_200kit_600_600.txt.npy\r\n",
      "sampled_out_mscoco_test_quora_coco_250k800_800.txt.npy\r\n",
      "sampled_out_mscoco_test_snli_200k600_600.txt.npy\r\n",
      "sampled_out_mscoco_test_snli_200kit_600_800.txt.npy\r\n",
      "sampled_out_mscoco_test_snli_coco_250kit_600_800.txt.npy\r\n",
      "sampled_out_mscoco_test_snli_coco_250kit_800_800.txt.npy\r\n",
      "sampled_out_mscoco_test_snli_quora_150k_600rnn.txt.npy\r\n",
      "sampled_out_mscoco_test_snli_quora_250kit_600_600.txt.npy\r\n",
      "sampled_out_mscoco_test_snli_quora_250kit_600_800.txt.npy\r\n",
      "sampled_out_quora_coco_200kit_600_600.txt.npy\r\n",
      "sampled_out_quora_coco_250k800_800.txt.npy\r\n",
      "sampled_out_quora_coco_250kit_600_800.txt.npy\r\n",
      "sampled_out_quoraonly120kit600decrnn.txt.npy\r\n",
      "sampled_out_quora_test_mscoco_300kit_600_800.txt.npy\r\n",
      "sampled_out_quora_test_quora_coco_200kit_600_600.txt.npy\r\n",
      "sampled_out_quora_test_quora_coco_250k800_800.txt.npy\r\n",
      "sampled_out_quora_test_snli_200k600_600.txt.npy\r\n",
      "sampled_out_quora_test_snli_200kit_600_800.txt.npy\r\n",
      "sampled_out_quora_test_snli_coco_250kit_600_800.txt.npy\r\n",
      "sampled_out_quora_test_snli_coco_250kit_800_800.txt.npy\r\n",
      "sampled_out_quora_test_snli_quora_150k_600rnn.txt.npy\r\n",
      "sampled_out_quora_test_snli_quora_250kit_600_600.txt.npy\r\n",
      "sampled_out_quora_test_snli_quora_250kit_600_800.txt.npy\r\n",
      "sampled_out_snips_mscoco_300kit_600_800.txt.npy\r\n",
      "sampled_out_snips_quora_coco_200kit_600_600.txt.npy\r\n",
      "sampled_out_snips_quora_coco_250k800_800.txt.npy\r\n",
      "sampled_out_snips_snli_200k600_600.txt.npy\r\n",
      "sampled_out_snips_snli_200kit_600_800.txt.npy\r\n",
      "sampled_out_snips_snli_coco_250kit_600_800.txt.npy\r\n",
      "sampled_out_snips_snli_coco_250kit_800_800.txt.npy\r\n",
      "sampled_out_snips_snli_quora_150k_600rnn.txt.npy\r\n",
      "sampled_out_snips_snli_quora_250kit_600_600.txt.npy\r\n",
      "sampled_out_snips_snli_quora_250kit_600_800.txt.npy\r\n",
      "sampled_out_snli_quora_150k_600rnn.txt.npy\r\n",
      "sampled_out_snli_quora_200k_800rnn.txt.npy\r\n",
      "sampled_out_snli_quora_250k_600_800rnn.txt.npy\r\n",
      "sampled_out_snli_quora_250k800_1100.txt.npy\r\n",
      "sampled_out_snli_test_mscoco_300kit_600_800.txt.npy\r\n",
      "sampled_out_snli_test_quora_coco_200kit_600_600.txt.npy\r\n",
      "sampled_out_snli_test_quora_coco_250k800_800.txt.npy\r\n",
      "sampled_out_snli_test_snli_200k600_600.txt.npy\r\n",
      "sampled_out_snli_test_snli_200kit_600_800.txt.npy\r\n",
      "sampled_out_snli_test_snli_coco_250kit_600_800.txt.npy\r\n",
      "sampled_out_snli_test_snli_coco_250kit_800_800.txt.npy\r\n",
      "sampled_out_snli_test_snli_quora_150k_600rnn.txt.npy\r\n",
      "sampled_out_snli_test_snli_quora_250kit_600_600.txt.npy\r\n",
      "sampled_out_snli_test_snli_quora_250kit_600_800.txt.npy\r\n",
      "sampled_out_.txt.npy\r\n",
      "sampled_out.txt.npy\r\n",
      "sampled_out_vocab25k200kit.txt.npy\r\n",
      "target_out_likely_snli_quora_200k_800rnn.txt.npy\r\n",
      "target_out_mean_quora_coco_200kit_600_600.txt.npy\r\n",
      "target_out_mean_quora_coco_250k800_800.txt.npy\r\n",
      "target_out_mean_quora_coco_250kit_600_800.txt.npy\r\n",
      "target_out_mscoco_300kit_600_800.txt.npy\r\n",
      "target_out_mscoco_test_mscoco_300kit_600_800.txt.npy\r\n",
      "target_out_mscoco_test_quora_coco_200kit_600_600.txt.npy\r\n",
      "target_out_mscoco_test_quora_coco_250k800_800.txt.npy\r\n",
      "target_out_mscoco_test_snli_200k600_600.txt.npy\r\n",
      "target_out_mscoco_test_snli_200kit_600_800.txt.npy\r\n",
      "target_out_mscoco_test_snli_coco_250kit_600_800.txt.npy\r\n",
      "target_out_mscoco_test_snli_coco_250kit_800_800.txt.npy\r\n",
      "target_out_mscoco_test_snli_quora_150k_600rnn.txt.npy\r\n",
      "target_out_mscoco_test_snli_quora_250kit_600_600.txt.npy\r\n",
      "target_out_mscoco_test_snli_quora_250kit_600_800.txt.npy\r\n",
      "target_out_quora_coco_200kit_600_600.txt.npy\r\n",
      "target_out_quora_coco_250k800_800.txt.npy\r\n",
      "target_out_quora_coco_250kit_600_800.txt.npy\r\n",
      "target_out_quoraonly120kit600decrnn.txt.npy\r\n",
      "target_out_quora_test_mscoco_300kit_600_800.txt.npy\r\n",
      "target_out_quora_test_quora_coco_200kit_600_600.txt.npy\r\n",
      "target_out_quora_test_quora_coco_250k800_800.txt.npy\r\n",
      "target_out_quora_test_snli_200k600_600.txt.npy\r\n",
      "target_out_quora_test_snli_200kit_600_800.txt.npy\r\n",
      "target_out_quora_test_snli_coco_250kit_600_800.txt.npy\r\n",
      "target_out_quora_test_snli_coco_250kit_800_800.txt.npy\r\n",
      "target_out_quora_test_snli_quora_150k_600rnn.txt.npy\r\n",
      "target_out_quora_test_snli_quora_250kit_600_600.txt.npy\r\n",
      "target_out_quora_test_snli_quora_250kit_600_800.txt.npy\r\n",
      "target_out_snips_mscoco_300kit_600_800.txt.npy\r\n",
      "target_out_snips_quora_coco_200kit_600_600.txt.npy\r\n",
      "target_out_snips_quora_coco_250k800_800.txt.npy\r\n",
      "target_out_snips_snli_200k600_600.txt.npy\r\n",
      "target_out_snips_snli_200kit_600_800.txt.npy\r\n",
      "target_out_snips_snli_coco_250kit_600_800.txt.npy\r\n",
      "target_out_snips_snli_coco_250kit_800_800.txt.npy\r\n",
      "target_out_snips_snli_quora_150k_600rnn.txt.npy\r\n",
      "target_out_snips_snli_quora_250kit_600_600.txt.npy\r\n",
      "target_out_snips_snli_quora_250kit_600_800.txt.npy\r\n",
      "target_out_snli_quora_150k_600rnn.txt.npy\r\n",
      "target_out_snli_quora_200k_800rnn.txt.npy\r\n",
      "target_out_snli_quora_250k_600_800rnn.txt.npy\r\n",
      "target_out_snli_quora_250k800_1100.txt.npy\r\n",
      "target_out_snli_test_mscoco_300kit_600_800.txt.npy\r\n",
      "target_out_snli_test_quora_coco_200kit_600_600.txt.npy\r\n",
      "target_out_snli_test_quora_coco_250k800_800.txt.npy\r\n",
      "target_out_snli_test_snli_200k600_600.txt.npy\r\n",
      "target_out_snli_test_snli_200kit_600_800.txt.npy\r\n",
      "target_out_snli_test_snli_coco_250kit_600_800.txt.npy\r\n",
      "target_out_snli_test_snli_coco_250kit_800_800.txt.npy\r\n",
      "target_out_snli_test_snli_quora_150k_600rnn.txt.npy\r\n",
      "target_out_snli_test_snli_quora_250kit_600_600.txt.npy\r\n",
      "target_out_snli_test_snli_quora_250kit_600_800.txt.npy\r\n",
      "target_out_.txt.npy\r\n",
      "target_out.txt.npy\r\n",
      "target_out_vocab25k200kit.txt.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
